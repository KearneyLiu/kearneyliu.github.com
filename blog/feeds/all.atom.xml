<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Kearney Liu's Home</title><link href="http://www.kearneyliu.com/" rel="alternate"></link><link href="http://www.kearneyliu.com/feeds/all.atom.xml" rel="self"></link><id>http://www.kearneyliu.com/</id><updated>2014-02-06T00:00:00+08:00</updated><entry><title>10000 Hours from Youtube</title><link href="http://www.kearneyliu.com/pages/2014/02/06/10000-hours-from-youtube.html" rel="alternate"></link><updated>2014-02-06T00:00:00+08:00</updated><author><name>Kearney Liu</name></author><id>tag:www.kearneyliu.com,2014-02-06:pages/2014/02/06/10000-hours-from-youtube.html</id><summary type="html">&lt;p&gt;&lt;em&gt;10000 Hours Episode 5&lt;/em&gt; has been on Youtube recently.&lt;/p&gt;
&lt;p&gt;I really love this series of documentary films. It talks about the intensive practice of basketball players. Well, I believe everything will be easy if you can practice something for 10000 hours. I will keep practicing programming and communication skills! &lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;As the documentary said, &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Break the wall and enjoy them.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;10000 Hours Episode 1:&lt;/p&gt;
&lt;iframe width="640" height="360" src="//www.youtube.com/embed/EEtpH6ZEPOc?rel=0" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;10000 Hours Episode 2 - Pay Off:&lt;/p&gt;
&lt;iframe width="640" height="360" src="//www.youtube.com/embed/2ZA_1Xpyqs0?rel=0" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;10000 Hours Episode 3:&lt;/p&gt;
&lt;iframe width="640" height="360" src="//www.youtube.com/embed/yfW4r0q3v0M?rel=0" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;10000 Hours Episode 4 - In The Lab:&lt;/p&gt;
&lt;iframe width="640" height="360" src="//www.youtube.com/embed/U-C6KELmp8U?rel=0" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;10000 Hours Episode 5 - Knight And Day:&lt;/p&gt;
&lt;iframe width="640" height="360" src="//www.youtube.com/embed/Svd-0F-uIOM?rel=0" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;</summary><category term="10000 Hours"></category></entry><entry><title>Happy Chinese New Year</title><link href="http://www.kearneyliu.com/pages/2014/01/31/happy-chinese-new-year.html" rel="alternate"></link><updated>2014-01-31T00:00:00+08:00</updated><author><name>Kearney Liu</name></author><id>tag:www.kearneyliu.com,2014-01-31:pages/2014/01/31/happy-chinese-new-year.html</id><summary type="html">&lt;p&gt;The Chinese Lunar New Year begins on today, Jan. 31, and marks the start of the Year of the Horse !!!&lt;/p&gt;
&lt;p&gt;I wish all people best of luck in 2014, and keep healthy!&lt;/p&gt;
&lt;p&gt;Also, I would like to get a good application result in this last year of my undergraduate study.&lt;/p&gt;</summary><category term="2014"></category><category term="Chinese New Year"></category></entry><entry><title>My Project &amp; Coursework Experience</title><link href="http://www.kearneyliu.com/pages/2014/01/15/my-project-coursework-experience.html" rel="alternate"></link><updated>2014-01-15T00:00:00+08:00</updated><author><name>Kearney Liu</name></author><id>tag:www.kearneyliu.com,2014-01-15:pages/2014/01/15/my-project-coursework-experience.html</id><summary type="html">&lt;p&gt;In the undergraduate study, I finished a lot of projects. Some of them are extracurricular, while some of them are course works. Therefore, I gained a lot of coding experience, and project management experience.&lt;/p&gt;
&lt;h3&gt;Independent Projects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;MyFont Designer - Personalized Calligraphy Application Development&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Spring 2013&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Developed a calligraphy recognition and reproduction application in Windows for Chinese handwritings.&lt;/li&gt;
&lt;li&gt;Designed an improved algorithm for Support Vector Machine to support the recognition and composition of character strokes.&lt;/li&gt;
&lt;li&gt;Developed a graphical user interface in C++ with Qt 5.0 framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Student Information Management System&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;December 2012&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Developed the system with C++ and SQL database to manage students’ information that includes academic status, grades, courses, and advisors.&lt;/li&gt;
&lt;li&gt;Designed a user-friendly interface that follows the structure principles of UI design.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Multimedia Retrieval Platform Research Project&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;September 2012&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Built the retrieval system framework on Xapian search engine in C++&lt;/li&gt;
&lt;li&gt;Used libcurl, a client-side URL transfer library, as a web crawler to collect web
pages.&lt;/li&gt;
&lt;li&gt;Took advantages of Institute of Computing Technology, Chinese Lexical Analysis
System(ICTCLAS) to segment Chinese words&lt;/li&gt;
&lt;li&gt;Applied probability-based methods for ranking the searching results.&lt;/li&gt;
&lt;li&gt;Achieved 95% grades in this project-based course.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Coursework&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Link Prediction over arXiv Dataset in “author-paper” Network&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;June 2013&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Employed Common Neighbors, rooted PageRank and weighted Katz algorithms to predict possible links in a social network.&lt;/li&gt;
&lt;li&gt;Applied receiver operating characteristic curve to evaluate above algorithms and discovered that weighted Katz performed better than the others in accuracy in most circumstances&lt;/li&gt;
&lt;li&gt;Achieved over 50% accuracy in a “small world” network&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Social Network Static Analysis over Friend Relationship Data Crawled from Renren.com&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;April 2013&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Designed a crawler for Renren.com (Chinese Facebook) to determine and collect users’ relationships with others&lt;/li&gt;
&lt;li&gt;Developed the crawler with concurrent programming frameworks in Python and drew relationship graphs with matplotlib package&lt;/li&gt;
&lt;li&gt;Analyzed static features of the network, and determined the most influential person on this social network&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Evaluation of Naïve Bayes, K-Nearest Neighbors, and Hidden Markov Model Algorithms Used in Optical Character Recognition&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;December 2012&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Applied the above three algorithms to OCR dataset provided by MIT Spoken Language Systems Group&lt;/li&gt;
&lt;li&gt;Proposed improvement of weighted-pixel point on HMM, making the precision improved 5%.&lt;/li&gt;
&lt;li&gt;On this dataset, KNN Model performs best with 90% precision.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Webpage Classification with Sequential Minimal Optimization Machine Learning Algorithm&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;October 2012&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Used Gaussian Kernel (non-linear) to classify webpages into seven categories with the WebKB dataset provided by Carnegie Mellon University.&lt;/li&gt;
&lt;li&gt;Combined parts of speech and words location in the webpage as features to train the support vector machines.&lt;/li&gt;
&lt;li&gt;Improved 10% precision on the testing results compared with TF-IDF method&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Development of Maze Solving Robot as an Autonomous Car Prototype&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;July 2012&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Designed an auto direction control system with infrared cameras&lt;/li&gt;
&lt;li&gt;Developed timing and alerting system in VHDL on MCS51 microcomputer&lt;/li&gt;
&lt;li&gt;Enabled the robot to cross the maze with the shortest time out of 90 teams in a championship&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Simulation of Multiple-Input-Multiple-Output(MIMO) System on Matlab&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;July 2013&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Applied space-time block code in the Rayleigh fading channel to distribute information&lt;/li&gt;
&lt;li&gt;Evaluated the performance of cascade process of STBC-Alamouti and convolution&lt;/li&gt;
&lt;li&gt;Simulated the entire system on Matlab, and drew bit error rate graphs to evaluate the properties.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Implementation of BCH Codes for FPGA in Verilog Hardware Description Language&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;June 2013&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encoded BCH codes (31,16) in the system, and allowed the codes to be processed 8 bits per clock cycle&lt;/li&gt;
&lt;li&gt;Used minimal hardware resources&lt;/li&gt;
&lt;/ul&gt;</summary><category term="Project"></category><category term="Coursework"></category><category term="Technology Experience"></category></entry><entry><title>My Research Experience</title><link href="http://www.kearneyliu.com/pages/2014/01/14/my-research-experience.html" rel="alternate"></link><updated>2014-01-14T00:00:00+08:00</updated><author><name>Kearney Liu</name></author><id>tag:www.kearneyliu.com,2014-01-14:pages/2014/01/14/my-research-experience.html</id><summary type="html">&lt;p&gt;In 2013, I did some projects of both research and industry. Moreover, in the whole undergraduate study, many projects and courseworks really help me improve my expertise skills and broaden my horizons. I will present my experience in a series of blogs:)&lt;/p&gt;
&lt;h3&gt;Industrial Research Experience&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;August, 2013 - Present&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;At first, I will highlight some points on this project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Natural Language Processing System with Machine Learning in Business Intelligence &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Collaboration with Asia Gateway, Beijing&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Performed text extraction and normalization for Chinese medical terms acquired from hospitals&lt;/li&gt;
&lt;li&gt;Optimized the Lucene Scoring algorithm with Vector Space Model for normalizing queries&lt;/li&gt;
&lt;li&gt;Improved the normalization precision by about 15% and F1-score by about 7%&lt;/li&gt;
&lt;li&gt;Designed a feedback system with machine learning to improve the precision of auto-normalization.&lt;/li&gt;
&lt;li&gt;Used on Apache Tomcat framework and processed terabytes of medical data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this industry-related research in the CSLT lab of Tsinghua University, I designed and developed a natural language processing system written in Java. I’m responsible for the term extraction and normalization for Chinese medical terms. In this project, I write codes with a more systematic thinking and attention to all the details such as naming the classes and functions, writing a well-organized Javadoc, comments of the codes, and communicating effectively with other engineers. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In the term extraction part, I need to pre-process the natural term, and segment the diagnosis, the drug into the right blank. Based on the system delimiter, I used regular expression (regex) to make them into segmentations, and load the medical ontology from the database, to extract drug general name, brand name, and chemical name from the segmentations in the algorithms of recursion, with the data structures of HashMap and ArrayList. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the normalization part, I used Luence, an information retrieval package for Java, to match the possible terms from normalized data in database. In addition, implementing vector space model, I improve the Lucene Score algorithm which is originally based on TF-IDF, and 15% precision rised. The whole system processed on Apache Tomcat framework, and I also designed a dispatching system to return the needed data if other people requests.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As this is my first industry project, I achieved many software development experience from my advisor and co-workers. I consider I will show better in the next stage of graduate study.&lt;/p&gt;
&lt;h3&gt;Research Experience&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;June, 2013 - Sep. 2013&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Opinion Mining and Sentiment Analysis of Twitter Data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Used dependency trees and machine learning methods to analyze the sentiment of tweets. &lt;/li&gt;
&lt;li&gt;Applied SenticNet and SentiWordNet lexicons to evaluate the results on Twitter.&lt;/li&gt;
&lt;li&gt;Proposed new ideas of more specific linguistic features of the dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When my spring course of 2013 come to an end, I started to do the research in the Center for Speech and Language Technologies in Tsinghua University. Under the supervision with Dr. Xia, a computer science professor in the Center, I gained intensive amount of hands-on experience of artificial intelligence research as well as advanced topics such as topic model and latent dirichlet allocation. The intellectual academic environment in the Center made me identify weakness, and search for improvement strategies by discussing with project managers and fellow student researchers. The research experiences have truly broadened my horizon and opened doors for me to develop original research ideas. &lt;/p&gt;
&lt;p&gt;At the beginning, I took several weeks to read some papers on opinion mining and tweets analysis. Having known the common methods for analyzing the text sentiment, I tried to use rule-based method to analyze the twitter data. With the tools of Stanford CoreNLP, I used dependency trees to extract the parts-of-speech(POS) of the text. Then, I used SenticNet and SentiWordNet, the sentiment lexicons to score the word, to score the whole sentence and evaluate whether it is a positive or negative sentence.&lt;/p&gt;
&lt;p&gt;In the second experiment, I used machine learning method to analyze the sentiment. With the help of support vector machine, I used the linguistic features like stop words, punctuation and emotion icon of twitter data as the features. Then, I compare the rule-based method with the machine-learning-based method, and find out the results of machine learning are better than that of dependency trees on the given data.&lt;/p&gt;
&lt;p&gt;Finally, I achieve a lot of research experience and I realize keeping asking "why" for the experiment.&lt;/p&gt;</summary><category term="Research"></category><category term="Industrial-related Research"></category></entry><entry><title>Deliverable &amp; Readable</title><link href="http://www.kearneyliu.com/pages/2013/09/30/deliverable-readable.html" rel="alternate"></link><updated>2013-09-30T00:00:00+08:00</updated><author><name>Kearney Liu</name></author><id>tag:www.kearneyliu.com,2013-09-30:pages/2013/09/30/deliverable-readable.html</id><summary type="html">&lt;p&gt;Recently, I am invloved into a project with full of energy, so I have not updated my blog for one month. However, I achieved many experience about designing and making a software, such as &lt;strong&gt;deliverable&lt;/strong&gt; and &lt;strong&gt;clean code&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;Deliverable&lt;/h3&gt;
&lt;p&gt;It's so important that we should finish our tasks before the due day when we are working. We should not make any excuse to explain why we do not work it out.Therefore, it's a big question that how I arrange my schdule of the task I have to work with.&lt;/p&gt;
&lt;p&gt;Because of majoring in Natural Language Processing, I am responsible for the part of term extraction and normalization in a business intelligence project. At first, I design how to design a data structure and interface for ten days. But I only have four weeks, and it's such a huge system. Then I start to code. &lt;/p&gt;
&lt;p&gt;Unfortunately, I encountered a problem that the data structure of a variable was false in the last few days. My mentor told me that the deliverable is so significant, do not waste others' time. So I have to stay up to revise my code. Finally, I completed it in the last two days and succeeded submiting it on time.&lt;/p&gt;
&lt;p&gt;Later, I should put the fuction of machine learning into the whole system, and the algorithm is so challenging to me.&lt;/p&gt;
&lt;h3&gt;Clean Code&lt;/h3&gt;
&lt;p&gt;Nowadays, we should make our code readable and clean. The code is not just read by the computer, but, in most of time, the code is read by co-workers. If someone spends too much time reading your code, he will be annoyed about your code and look upon down your coding ability.&lt;/p&gt;
&lt;p&gt;There is a saying from Bjarne Stroustrup:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I love elegant and efficient code&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He also mentions the code needs to be logic and each function must be abstracted. In addition, how to name the function as well as the comments, commit logs are designed to be clean. &lt;/p&gt;
&lt;p&gt;In this project, I experienced the clean code a lot. Elegant code may help us improve the efficiency a lot. So we can save a lot of time of reading others' code.&lt;/p&gt;
&lt;p&gt;In the future, I would make my best to make code cleaner in order to keep a good coding principle.&lt;/p&gt;</summary><category term="Project"></category></entry><entry><title>Some papers I read about Opinion Mining and Sentiment Analysis and my notes</title><link href="http://www.kearneyliu.com/pages/2013/08/19/some-papers-i-read-about-opinion-mining-and-sentiment-analysis-and-my-notes.html" rel="alternate"></link><updated>2013-08-19T00:00:00+08:00</updated><author><name>Kearney Liu</name></author><id>tag:www.kearneyliu.com,2013-08-19:pages/2013/08/19/some-papers-i-read-about-opinion-mining-and-sentiment-analysis-and-my-notes.html</id><summary type="html">&lt;p&gt;My research interest is &lt;strong&gt;Opinion Mining and Sentiment Analysis&lt;/strong&gt;. These days I read a lot of papers. Here are some of them. Share with you.&lt;/p&gt;
&lt;h3&gt;Sentiment Analysis of Twitter Data&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Apoorv Agarwal, ACL 2011&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Main Approaches&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;POS-specific prior polarity feature&lt;/li&gt;
&lt;li&gt;tree kernel to obviate the need for tedious feature engineering &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Notes&lt;/h4&gt;
&lt;p&gt;In all, the author just care more about the polarity of English word(non-stop) and its POS features. Besides, he proposes two models compared with baseline(unigram), and proves his methods are greater than the baseline. However, I think there may be some improvements, for instance, to use Standford NLP implement and achieve more info about the tree.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Merging SenticNet and WordNet-Affect Emotion Lists for Sentiment Analysis&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Soujanya Porial, ICSP2012&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Main motivation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;adding new useful information to SenticNet entries&lt;/li&gt;
&lt;li&gt;Expanding WordNet-Affect emotion lists with the SenticNet concepts&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Main approach&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;For classification, the author used two kinds of features of the concepts &lt;/li&gt;
&lt;li&gt;ISEAR data-based features&lt;/li&gt;
&lt;li&gt;Features based on similarity measures&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Notes&lt;/h4&gt;
&lt;p&gt;This paper tells us how to expand a exiting sentiment lexicon to involve more words. The method he uses is excellent, and enlightens me how to expand the SenticNet lexicon.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Semantic Sentiment Analysis of Twitter&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Hassan Saif, Iswc2012&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Main Approach&lt;/h4&gt;
&lt;p&gt;Introduce and implement a new set of semantic features for training a model for sentiment analysis of tweets.&lt;/p&gt;
&lt;p&gt;a new type of features for sentiment analysis, called semantic features, where for each entity in a tweet (e.g. iPhone, iPad, MacBook), the abstract concept that represents it will be added as a new feature (e.g. Apple product)&lt;/p&gt;
&lt;h4&gt;Notes&lt;/h4&gt;
&lt;p&gt;In this paper, the author extracts each entity in a tweet, and make up the concept. But I think it may be too sparse, if some tweets does not involve these words, the results could not be good. &lt;/p&gt;</summary><category term="Sentiment Analysis"></category><category term="Twitter"></category><category term="Paper"></category></entry><entry><title>Hello, BLOG!</title><link href="http://www.kearneyliu.com/pages/2013/08/14/hello-blog.html" rel="alternate"></link><updated>2013-08-14T00:00:00+08:00</updated><author><name>Kearney Liu</name></author><id>tag:www.kearneyliu.com,2013-08-14:pages/2013/08/14/hello-blog.html</id><summary type="html">&lt;p&gt;This is my own blog and I will tell what I think to the world!&lt;/p&gt;</summary><category term="Hello"></category></entry></feed>