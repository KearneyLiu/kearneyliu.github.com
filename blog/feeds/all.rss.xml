<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kearney Liu's Home</title><link>http://www.kearneyliu.com/</link><description></description><atom:link href="http://www.kearneyliu.com/feeds/all.rss.xml" rel="self"></atom:link><lastBuildDate>Tue, 14 Jan 2014 00:00:00 +0800</lastBuildDate><item><title>My Research Experience</title><link>http://www.kearneyliu.com/pages/2014/01/14/my-research-experience.html</link><description>&lt;p&gt;In 2013, I did some projects of both research and industry. Moreover, in the whole undergraduate study, many projects and courseworks really help me improve my expertise skills and broaden my horizons. I will present my experience in a series of blogs:)&lt;/p&gt;
&lt;h3&gt;Industrial Research Experience&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;August, 2013 - Present&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;At first, I will highlight some points on this project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Natural Language Processing System with Machine Learning in Business Intelligence &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Collaboration with Asia Gateway, Beijing&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Performed text extraction and normalization for Chinese medical terms acquired from hospitals&lt;/li&gt;
&lt;li&gt;Optimized the Lucene Scoring algorithm with Vector Space Model for normalizing queries&lt;/li&gt;
&lt;li&gt;Improved the normalization precision by about 15% and F1-score by about 7%&lt;/li&gt;
&lt;li&gt;Designed a feedback system with machine learning to improve the precision of auto-normalization.&lt;/li&gt;
&lt;li&gt;Used on Apache Tomcat framework and processed terabytes of medical data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this industry-related research in the CSLT lab of Tsinghua University, I designed and developed a natural language processing system written in Java. Iâ€™m responsible for the term extraction and normalization for Chinese medical terms. In this project, I write codes with a more systematic thinking and attention to all the details such as naming the classes and functions, writing a well-organized Javadoc, comments of the codes, and communicating effectively with other engineers. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In the term extraction part, I need to pre-process the natural term, and segment the diagnosis, the drug into the right blank. Based on the system delimiter, I used regular expression (regex) to make them into segmentations, and load the medical ontology from the database, to extract drug general name, brand name, and chemical name from the segmentations in the algorithms of recursion, with the data structures of HashMap and ArrayList. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the normalization part, I used Luence, an information retrieval package for Java, to match the possible terms from normalized data in database. In addition, implementing vector space model, I improve the Lucene Score algorithm which is originally based on TF-IDF, and 15% precision rised. The whole system processed on Apache Tomcat framework, and I also designed a dispatching system to return the needed data if other people requests.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As this is my first industry project, I achieved many software development experience from my advisor and co-workers. I consider I will show better in the next stage of graduate study.&lt;/p&gt;
&lt;h3&gt;Research Experience&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;June, 2013 - Sep. 2013&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Opinion Mining and Sentiment Analysis of Twitter Data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Used dependency trees and machine learning methods to analyze the sentiment of tweets. &lt;/li&gt;
&lt;li&gt;Applied SenticNet and SentiWordNet lexicons to evaluate the results on Twitter.&lt;/li&gt;
&lt;li&gt;Proposed new ideas of more specific linguistic features of the dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When my spring course of 2013 come to an end, I started to do the research in the Center for Speech and Language Technologies in Tsinghua University. Under the supervision with Dr. Xia, a computer science professor in the Center, I gained intensive amount of hands-on experience of artificial intelligence research as well as advanced topics such as topic model and latent dirichlet allocation. The intellectual academic environment in the Center made me identify weakness, and search for improvement strategies by discussing with project managers and fellow student researchers. The research experiences have truly broadened my horizon and opened doors for me to develop original research ideas. &lt;/p&gt;
&lt;p&gt;At the beginning, I took several weeks to read some papers on opinion mining and tweets analysis. Having known the common methods for analyzing the text sentiment, I tried to use rule-based method to analyze the twitter data. With the tools of Stanford CoreNLP, I used dependency trees to extract the parts-of-speech(POS) of the text. Then, I used SenticNet and SentiWordNet, the sentiment lexicons to score the word, to score the whole sentence and evaluate whether it is a positive or negative sentence.&lt;/p&gt;
&lt;p&gt;In the second experiment, I used machine learning method to analyze the sentiment. With the help of support vector machine, I used the linguistic features like stop words, punctuation and emotion icon of twitter data as the features. Then, I compare the rule-based method with the machine-learning-based method, and find out the results of machine learning are better than that of dependency trees on the given data.&lt;/p&gt;
&lt;p&gt;Finally, I achieve a lot of research experience and I realize keeping asking "why" for the experiment.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kearney Liu</dc:creator><pubDate>Tue, 14 Jan 2014 00:00:00 +0800</pubDate><guid>tag:www.kearneyliu.com,2014-01-14:pages/2014/01/14/my-research-experience.html</guid><category>Research</category><category>Industrial-related Research</category></item><item><title>Deliverable &amp; Readable</title><link>http://www.kearneyliu.com/pages/2013/09/30/deliverable-readable.html</link><description>&lt;p&gt;Recently, I am invloved into a project with full of energy, so I have not updated my blog for one month. However, I achieved many experience about designing and making a software, such as &lt;strong&gt;deliverable&lt;/strong&gt; and &lt;strong&gt;clean code&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;Deliverable&lt;/h3&gt;
&lt;p&gt;It's so important that we should finish our tasks before the due day when we are working. We should not make any excuse to explain why we do not work it out.Therefore, it's a big question that how I arrange my schdule of the task I have to work with.&lt;/p&gt;
&lt;p&gt;Because of majoring in Natural Language Processing, I am responsible for the part of term extraction and normalization in a business intelligence project. At first, I design how to design a data structure and interface for ten days. But I only have four weeks, and it's such a huge system. Then I start to code. &lt;/p&gt;
&lt;p&gt;Unfortunately, I encountered a problem that the data structure of a variable was false in the last few days. My mentor told me that the deliverable is so significant, do not waste others' time. So I have to stay up to revise my code. Finally, I completed it in the last two days and succeeded submiting it on time.&lt;/p&gt;
&lt;p&gt;Later, I should put the fuction of machine learning into the whole system, and the algorithm is so challenging to me.&lt;/p&gt;
&lt;h3&gt;Clean Code&lt;/h3&gt;
&lt;p&gt;Nowadays, we should make our code readable and clean. The code is not just read by the computer, but, in most of time, the code is read by co-workers. If someone spends too much time reading your code, he will be annoyed about your code and look upon down your coding ability.&lt;/p&gt;
&lt;p&gt;There is a saying from Bjarne Stroustrup:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I love elegant and efficient code&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He also mentions the code needs to be logic and each function must be abstracted. In addition, how to name the function as well as the comments, commit logs are designed to be clean. &lt;/p&gt;
&lt;p&gt;In this project, I experienced the clean code a lot. Elegant code may help us improve the efficiency a lot. So we can save a lot of time of reading others' code.&lt;/p&gt;
&lt;p&gt;In the future, I would make my best to make code cleaner in order to keep a good coding principle.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kearney Liu</dc:creator><pubDate>Mon, 30 Sep 2013 00:00:00 +0800</pubDate><guid>tag:www.kearneyliu.com,2013-09-30:pages/2013/09/30/deliverable-readable.html</guid><category>Project</category></item><item><title>Some papers I read about Opinion Mining and Sentiment Analysis and my notes</title><link>http://www.kearneyliu.com/pages/2013/08/19/some-papers-i-read-about-opinion-mining-and-sentiment-analysis-and-my-notes.html</link><description>&lt;p&gt;My research interest is &lt;strong&gt;Opinion Mining and Sentiment Analysis&lt;/strong&gt;. These days I read a lot of papers. Here are some of them. Share with you.&lt;/p&gt;
&lt;h3&gt;Sentiment Analysis of Twitter Data&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Apoorv Agarwal, ACL 2011&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Main Approaches&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;POS-specific prior polarity feature&lt;/li&gt;
&lt;li&gt;tree kernel to obviate the need for tedious feature engineering &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Notes&lt;/h4&gt;
&lt;p&gt;In all, the author just care more about the polarity of English word(non-stop) and its POS features. Besides, he proposes two models compared with baseline(unigram), and proves his methods are greater than the baseline. However, I think there may be some improvements, for instance, to use Standford NLP implement and achieve more info about the tree.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Merging SenticNet and WordNet-Affect Emotion Lists for Sentiment Analysis&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Soujanya Porial, ICSP2012&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Main motivation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;adding new useful information to SenticNet entries&lt;/li&gt;
&lt;li&gt;Expanding WordNet-Affect emotion lists with the SenticNet concepts&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Main approach&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;For classification, the author used two kinds of features of the concepts &lt;/li&gt;
&lt;li&gt;ISEAR data-based features&lt;/li&gt;
&lt;li&gt;Features based on similarity measures&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Notes&lt;/h4&gt;
&lt;p&gt;This paper tells us how to expand a exiting sentiment lexicon to involve more words. The method he uses is excellent, and enlightens me how to expand the SenticNet lexicon.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Semantic Sentiment Analysis of Twitter&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Hassan Saif, Iswc2012&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Main Approach&lt;/h4&gt;
&lt;p&gt;Introduce and implement a new set of semantic features for training a model for sentiment analysis of tweets.&lt;/p&gt;
&lt;p&gt;a new type of features for sentiment analysis, called semantic features, where for each entity in a tweet (e.g. iPhone, iPad, MacBook), the abstract concept that represents it will be added as a new feature (e.g. Apple product)&lt;/p&gt;
&lt;h4&gt;Notes&lt;/h4&gt;
&lt;p&gt;In this paper, the author extracts each entity in a tweet, and make up the concept. But I think it may be too sparse, if some tweets does not involve these words, the results could not be good. &lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kearney Liu</dc:creator><pubDate>Mon, 19 Aug 2013 00:00:00 +0800</pubDate><guid>tag:www.kearneyliu.com,2013-08-19:pages/2013/08/19/some-papers-i-read-about-opinion-mining-and-sentiment-analysis-and-my-notes.html</guid><category>Sentiment Analysis</category><category>Twitter</category><category>Paper</category></item><item><title>Hello, BLOG!</title><link>http://www.kearneyliu.com/pages/2013/08/14/hello-blog.html</link><description>&lt;p&gt;This is my own blog and I will tell what I think to the world!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kearney Liu</dc:creator><pubDate>Wed, 14 Aug 2013 00:00:00 +0800</pubDate><guid>tag:www.kearneyliu.com,2013-08-14:pages/2013/08/14/hello-blog.html</guid><category>Hello</category></item></channel></rss>